\chapter{外文资料的调研阅读报告或书面翻译}

\title{知识图谱填充任务中实体与关系的表示学习}

{\heiti 摘要：} 

知识图谱填充是一个预测知识图谱实体间链接关系类型的任务。在本篇论文中，我们提出了一个知识图谱嵌入的算法来解决这个问题。在最近的研究中，诸如 TransE 和 TransR 这样的模型将关系作为头实体到尾实体之间的转移来对知识图谱进行嵌入。通常，这类算法会将实体和关系在同一个连续空间中进行嵌入。实际上，一个实体可能有多个方面，即在不同关系下拥有不同的意义，这使得在一个统一的空间中建模变的很困难。在本文中，我们提出了叫作 TransR 的模型来将实体和关系在不同空间中嵌入。然后，在这个模型中我们再学习实体空间和关系空间的映射关系，从而将实体从实体空间映射到关系空间中来构建头实体到尾实体之间的转移。在试验中，我们在三个任务上评测了我们的模型，包括链接预测，三元组分类和关系现实抽取。实验结果和之前最好的模型相比有显著的提升，这些模型中包括 TransE 和 TransH。这篇论文的源代码被我们公布在 https://github.com/mrlyk423/relation\_extractio 上。

\section{引言}

  \begin{figure}[htb]
  \centering
  \includegraphics[width=0.8\columnwidth]{figures/trans/model_idea}
  \caption{Simple illustration of TransR.}
  \label{fig_1:idea}
  \end{figure}

知识图谱可以将实体和实体间丰富的关系信息进行结构化。尽管一个经典的知识图谱可能含有数百万个实体和数以亿个关系事实，这个图谱离完善还差的很远。知识图谱填充这个任务就是为了在已有图谱信息的监督下进行学习并能够预测实体间的未知关系。这个任务可以推理出新的关系事实，从而也对从自由文本中进行关系抽取有很重要的作用。

知识图谱填充和社交网络中的链接预测非常相似，但是更具有挑战性，主要原因有以下几点：（1）知识图谱中的节点代表的实体通常具有不同的关系与属性；（2）知识图谱中的边代表的关系也是有不同类型的。对于知识图谱填充，我们不仅需要知道实体之间是否有关系还要知道这个关系是哪种具体的类型。

因为这个原因，传统的用来做链接预测的方法对于图谱填充是不适用的。最近，一个极有发展潜力的模型被提出用来将知识图谱嵌入到一个连续的向量空间中同时在空间中保持图的特性。紧跟着这个工作，大量的方法被尝试和提出，这个我们将会在``相关工作''章节细节阐述。

在这些方法中，TransE \cite{bordes2013translating} 和 TransH \cite{wang2014knowledge} 最为简洁有效，并且取得了最好的预测效果。受 \cite{mikolov2013distributed} 的启发，TransE 将实体和关系都嵌入为空间中的向量。这些向量的维度为 $\mathbb{R}^k$，我们也用加粗的符号来代表对应的向量。Trans 最基本的想法就是将实体之间的关系对应到实体向量间的转移，即知识图谱中的三元组$(h, r, t)$，我们有$\mathbf{h} + \mathbf{r} \approx \mathbf{t}$。因为 TransE 对于 1-to-N、N-to-1、N-to-N 的关系建模有一定的问题，TransH 被提出以便将实体在不同的关系下拥有不同的表示从而适应这种非一对一的关系。

无论是 TransE 还是 TransH 都将实体和关系嵌入到同一个$\mathbb{R}^k$的空间中去。但是，我们之前说到的，一个实体在不同的关系下是有所区别的。因此，有这样一个显而易见的现象，相似的实体会在空间上非常接近，但是在不同的关系背景下我们又希望它们有区分性，即距离上要相互远离，这两者在同一个空间中是矛盾的。为了解决这个问题，我们提出了一个新的方法，将实体和关系在各自的空间中进行嵌入，例如实体在一个实体空间中，不同类型的关系在不同的关系空间中，并且要构建一个映射机制能够将实体从实体空间映射到不同的关系空间中去，我们将这个方法命名为 TransR。

TransR 的基础想法如图\ref{fig_1:idea}所示。对于一个给定的三元组$(h, r, t)$，实体首先从实体空间被映射到关系$r$所在的关系空间中去成为$h_r$和$t_r$，映射为$M_r$，然后有$\mathbf{h}_r + \mathbf{r} \approx \mathbf{t}_r$。通过这样的一种映射，我们可以使得头尾实体能够在空间中具有相似性，而在不同的关系中又有不同的空间表现。

更进一步，即使在同一个类型的关系下，实体间的潜在关联也是具有多样性的。所以即使对于每一个关系都构建一个向量也是不够的。举个例子，头尾之间的关系``行政区划覆盖''可能具有很多中关系模式，比如``国家-城市''、``国家-大学''、``洲-国家''等等。受到分段线性回归 \cite{ritzema1994drainage} 的启发，我们通过将头尾实体间的潜在关系进行聚类，并为每一个聚类的簇单独建立向量表示的方法进一步拓展了TransR，并且命名为 CTransR。
 
我们在三个任务上评测了我们的模型，包括链接预测，三元组分类和关系现实抽取，数据也是从WordNet和Freebase中抽取出专门用来做性能评测的标准数据集。实验结果和之前最好的模型相比有显著的提升，体现了我们模型的有效性。

\section{相关工作}

    \subsection{TransE和TransH}

    正如我们在``引言''中介绍的那样，TransE \cite{bordes2013translating} 希望图谱中的三元组$(h, r, t)$满足$\mathbf{h} + \mathbf{r} \approx \mathbf{t}$。这表明$(\mathbf{t})$在空间中应该是最接近$(\mathbf{h} + \mathbf{r})$的。因此，TransE 定义了这样一个评分函数：
    \begin{equation}
    f_{r}(h, t) = \|\mathbf{h} + \mathbf{r} - \mathbf{t}\|_{2}^{2}，
    \end{equation}
    函数值越低代表$(h, r, t)$存在的可能性越大，反之亦然。

    TransE 在 1-to-1 的关系上表现突出，但是在 N-to-1, 1-to-N 以及 N-to-N 这些类别的关系上存在问题。我们以一个 1-to-N 类别的关系$r$作为案例。$\forall i \in \{0, \ldots, m\}, (h_i, r, t) \in S$. 这表明$\mathbf{h}_0 = \ldots = \mathbf{h}_m$，然而这和实际现象是违背的。

    为了解决TransE在 N-to-1, 1-to-N 以及 N-to-N 类别关系上的问题，TransH \cite{wang2014knowledge} 被提了出来，并用以将实体在不同关系的环境下嵌入不同的分布式表示向量里去。对于任意的关系$r$，TransH 将关系建模为一个法向量为$\mathbf{w}_r$的超平面上的向量$\mathbf{r}$。对于任意一个三元组$(h, r, t)$，



    实体的向量$\mathbf{h}$和$\mathbf{t}$首先被映射到$\mathbf{w}_r$的超平面上成为$\mathbf{h}_{\bot}$和$\mathbf{t}_{\bot}$，接着和TransE类似的定义出评分函数：
    \begin{equation}
    f_{r}(h, t) = \|\mathbf{h}_{\bot} + \mathbf{r} - \mathbf{t}_{\bot}\|_{2}^{2}。
    \end{equation}
    在$\|\mathbf{w}_r\|_{2} = 1$的约束下, 参数满足$\mathbf{h}_{\bot} = \mathbf{h} - \mathbf{w}_{r}^{\top}\mathbf{h}\mathbf{w}_{r}$，以及$\mathbf{t}_{\bot} = \mathbf{t} - \mathbf{w}_{r}^{\top}\mathbf{t}\mathbf{w}_{r}$。正是通过将实体向量映射到关系超平面上，我们使得实体在不同的关系环境下有不同的表示。


    \subsection{其他模型}
    除了 TransE 和 TransH，还有许多其他模型可以用来对知识图谱进行嵌入。这里我们介绍一些经典的模型方案，并且也会作为我们的实验对比在实验环节体现。

    \textbf{Unstructured Model (UM)。} UM \cite{bordes2012joint,bordes2014semantic} 是一个简化版本的 TransE，即在 TransE 的基础上满足$\mathbf{r} = \mathbf{0}$, 此时我们的评分函数为$f_r(h, t) =  \|\mathbf{h} - \mathbf{t}\|_{2}^{2}$。很显然，这个模型无法处理实体间多种关系的情况。

    \textbf{Structured Embedding (SE)。} SE \cite{bordes2011learning} 为头实体和尾实体设计了不同的变换矩阵，比如$\mathbf{M}_{r, 1}$和$\mathbf{M}_{r, 2}$，并且在这些变换矩阵的基础上定义了$L_1$距离的评分函数，$f_r(h, t) =  \| \mathbf{M}_{r, 1} \mathbf{h} - \mathbf{M}_{r, 2} \mathbf{t} \|_1$。由于模型具有两个独立的变换矩阵，因此不能捕获实体和关系之间的精确关系。

    \textbf{Single Layer Model (SLM)。} SLM 是 NTN \cite{socher2013reasoning}的简化版本。评分函数如下：
    \begin{equation}
    f_{r}(h, t) = \mathbf{u}_r^\top g (\mathbf{M}_{r, 1} \mathbf{h} + \mathbf{M}_{r, 2} \mathbf{t})，
    \end{equation}
    这里$\mathbf{M}_{r, 1}$和$\mathbf{M}_{r, 2}$是权重矩阵，$g()$是\texttt{tanh}操作。SLM 是 NTN 在张量被设置为$\mathbf{0}$时的特例。


    \textbf{Semantic Matching Energy (SME)。} SME \cite{bordes2012joint,bordes2014semantic} 可以通过多重矩阵乘法和哈达玛积来获取实体和关系之间的相关性。SME 模型将关系表示为一个独立的向量，这些向量通过线性矩阵乘积与实体向量相互作用，并且关系向量内部共享相同的参数。SME 定义了两个语义能量函数用于优化，包括线性形式：
    \begin{equation}
    f_r(h, t) = (\mathbf{M}_{1} \mathbf{h} + \mathbf{M}_{2} \mathbf{r} + \mathbf{b}_1 )^{\top} (\mathbf{M}_{3} \mathbf{t} + \mathbf{M}_{4} \mathbf{r} + \mathbf{b}_2)，
    \end{equation}
    和双线性形式：
    \begin{equation}
    f_r(h, t) = \big( (\mathbf{M}_{1} \mathbf{h}) \otimes (\mathbf{M}_{2} \mathbf{r}) + \mathbf{b}_1 \big)^{\top} \big( (\mathbf{M}_{3} \mathbf{t}) \otimes (\mathbf{M}_{4} \mathbf{r}) + \mathbf{b}_2 \big)，
    \end{equation}
    这里$\mathbf{M}_{1}$，$\mathbf{M}_{2}$，$\mathbf{M}_{3}$和$\mathbf{M}_{4}$是权重矩阵，$\otimes$是哈达玛积，$\mathbf{b}_1$和$\mathbf{b}_2$是线性偏置向量。在 \cite{bordes2014semantic}的工作中，SME 的双线性形式被重新定义为三路张量而不是矩阵。

    \textbf{Latent Factor Model (LFM)。} LFM \cite{jenatton2012latent,sutskever2009modelling} 考虑使用实体嵌入之间的二阶相关性来定义一个双线性评分函数$f_r(h, t) = \mathbf{h}^{\top}\mathbf{M}_r\mathbf{t}$。

    \textbf{Neural Tensor Network (NTN)。} NTN \cite{socher2013reasoning} 定义了一个表达能力很强的评分函数：
    \begin{equation}
    f_{r}(h, t) = \mathbf{u}_r^\top g (\mathbf{h}^{\top} \mathbf{M}_r \mathbf{t} + \mathbf{M}_{r, 1} \mathbf{h} + \mathbf{M}_{r, 2}\mathbf{t} + \mathbf{b}_r)，
    \end{equation}
    这里$\mathbf{u}_r$是一个针对关系的线性变换层，$g()$是\texttt{tanh}操作，$\mathbf{M}_r \in \mathbb{R}^{d \times d \times k}$是一个三路的张量，$\mathbf{M}_{r, 1}, \mathbf{M}_{r, 2} \in  \mathbb{R}^{k\times d}$则是权重矩阵。在表达能力强的同时，NTN 的高复杂度使得它很难在大规模知识图谱上被应用。

    考虑到时间问题，在实验部分我们将会和\textbf{RESCAL}, 一个 \cite{nickel2011three,nickel2012factorizing} 提出的类似的矩阵分解算法来对比。


    \section{我们的模型}
    \label{sec:method}

    为了解决 TransE 和 TransH 在表示学习中的一些问题，我们提出了 TransR ，该模型可以将实体和关系在不同的空间中进行嵌入，并且通过特殊的矩阵将实体映射到关系空间中。

    \subsection{TransR}


    TransE 和 TransH 都将实体和关系嵌入到相同的维度为$\mathbb{R}^k$的空间中去。实际上，关系和实体是完全不同概念的事物，在同一个语义空间中将这些东西同时嵌入是有一些问题的。尽管 TransH 通过关系的超平面假设让实体在不同关系下具有了一定的自由度，但是仍然无法突破同一个空间带来的约束。为解决这个问题，我们提出了新的方法将实体和关系嵌入到不同的空间中去，比如\textbf{实体空间}和\textbf{关系空间}，并且在关系空间中采取了类似 TransE 和 TransH 的转移特性，我们将模型命名为TransR。

    在 TransR 中，对于每一个三元组$(h, r, t)$，实体向量定义为$\mathbf{h}, \mathbf{t} \in \mathbb{R}^k$，关系向量定义为$\mathbf{r} \in \mathbb{R}^d$。值得注意的是，因为在不同空间中，所以实体和关系向量的维度可以是不同的，即$k \ne d$。

    对于特定的关系$r$，我们定义映射矩阵$\mathbf{M}_{r} \in \mathbb{R}^{k \times d}$将实体映射到关系空间中。通过这个映射矩阵，我们可以定义映射之后的实体向量：
    \begin{equation}
    \mathbf{h}_{r} = \mathbf{h}\mathbf{M}_r, \quad \mathbf{t}_{r} = \mathbf{t}\mathbf{M}_r。
    \end{equation}
    因而，评分函数可以定义为：
    \begin{equation}
    f_{r}(h, t) = \|\mathbf{h}_r + \mathbf{r} - \mathbf{t}_r\|_{2}^{2}。
    \end{equation}
    在此基础上，我们加上了约束使得$h$, $r$, $t$的向量和映射矩阵满足$\forall h, r, t$，$\|\mathbf{h}\|_2\le1,\|\mathbf{r}\|_2\le1, \|\mathbf{t}\|_2\le1, \|\mathbf{h}\mathbf{M_r}\|_2\le1, \|\mathbf{t}\mathbf{M_r}\|_2\le1$.

    \subsection{基于聚类的 TransR (CTransR)}
    之前提到的模型，包括 TransE, TransH 和 TransR，均是为每个关系学习一个单独的向量，但是这往往是不能覆盖所有实体对之间的潜在关系的，因为这些关系往往在不同的语境下具有多样性。为了更好的将一种关系下的多个子类型区分开来，我们引入了多重线性回归 \cite{ritzema1994drainage} 的思路来拓展 TransR。

    基本的思路是这样的，我们首先我们将训练的案例分为若干组。对于特定的关系$r$，所有训练数据中蕴含这个关系的实体对$(h, t)$将会被聚类到若干组中，并且聚类到同一组里的实体对拥有相同的关系并且和$r$的向量接近。对于所有的实体对$(h, t)$ 将使用它们的向量运算$(\mathbf{h} - \mathbf{t})$来聚类。然后为每个聚类结果学习得到一个单独的新的向量$\mathbf{r}_c$和映射矩阵$\mathbf{M}_{r}$。我们将映射的实体向量定义为$\mathbf{h}_{r,c} = \mathbf{h}\mathbf{M}_{r}$和$\mathbf{t}_{r,c} = \mathbf{t}\mathbf{M}_{r}$，而评分函数也被定义为：
    \begin{equation}
    f_{r}(h, t) = \|\mathbf{h}_{r, c} + \mathbf{r}_c - \mathbf{t}_{r, c}\|_{2}^{2} + \alpha \|\mathbf{r}_{c} - \mathbf{r}\|_{2}^{2}，
    \end{equation}
    这里$\|\mathbf{r}_{c} - \mathbf{r}\|_{2}^{2}$用来约束聚类成的关系向量$\mathbf{r}_{c}$离原始的关系向量$\mathbf{r}$在距离上不是很远，$\alpha$用来调节这个约束对损失函数的影响。除此以外，和 TransR 一样，CTransR 也要强行约束$h, r, t$的向量以及映射矩阵。

    \subsection{训练方法和实现细节}
    我们定义了以下一个基于边界值的损失函数作为我们的训练目标，
    \begin{equation}
    L = \sum_{(h, r, t) \in S}\sum_{(h', r, t') \in S'}\max \big( 0, f_r(h, t) + \gamma - f_r(h', t')\big)，
    \end{equation}
    这里$\max(x,y)$用来在$x$ 和 $y$中选取一个最大值，$\gamma$ 就是边界值, $S$是正例的三元组集合而$S'$是负例的三元组集合。

    知识图谱中只存在正例三元组，所以我们通过从正例三元组集合$(h, r, t) \in S$中替换实体来构建负例三元组集合$(h', r, t') \in S'$。当替换三元组的实体时，我们遵循 \cite{wang2014knowledge} 中提出的方法并且采用不同概率来替换头尾实体。对于 1-to-N、N-to-1、N-to-N 这样的关系, 我们会对其中``1''这边的实体给予更多的关注和更大的概率来生成负例。在试验中，我们将过去一贯的采样方法命名为``unif''并且将这个 \cite{wang2014knowledge} 提出的新的方法命名为``bern''。

    TransR 和 CTransR 的模型学习方法采用了随机梯度下降（stochastic gradient descent，SGD）。为了避免过拟合，我们用 TransE 的结果来初始化实体和关系向量，并且用单位阵来初始化映射矩阵。


    \section{实验和分析}
    \label{sec:experiment}

    \subsection{数据集合和实验设置}
    在这篇论文中，我们在两个经典数据集合上评测了我们的方法，WordNet \cite{miller1995wordnet} 和 Freebase \cite{bollacker2008freebase}。WordNet 提供了一个词语级别的语义知识图谱。在 WordNet 中，每个实体都是一个包含若干个词语的\emph{同义词集合}并对应一个单独的\emph{词语意义}。而关系则被定义为同义词集合之间的词汇关联，比如\texttt{上位词}, \texttt{下位词}, \texttt{局部词} and \texttt{整体词}。在本文中，我们采用了两个来源于 WordNet 的数据集合，其中\texttt{WN18}曾被用在 \cite{bordes2014semantic} 中，而\texttt{WN11}被用在 \cite{socher2013reasoning} 中。\texttt{WN18}包含了$18$种关系类型，而\texttt{WN11}包含了$11$中关系类型。Freebase 中提供的是这个世界上的通用知识。举个例子，三元组（乔布斯, 建立, 苹果公司）表述了在姓名实体\emph{乔布斯}和组织实体\emph{苹果公司}之间的关系为\texttt{建立}关系，即乔布斯建立了苹果公司。在本篇论文中，我们同样采用了两个来源于 Freebase 的数据集合，\texttt{FB15K} 曾被用在 \cite{bordes2014semantic} 中，而 \texttt{FB13} 曾被用在 \cite{socher2013reasoning} 中。我们将数据集合的具体数据罗列在表\ref{table_1:statistics}中。

    \begin{table}[h]
    \small
    \centering
    \caption{WN18、FB15K、WN11、FB40K 的数据细节}
    \label{table_1:statistics}
    \begin{tabular}{|c|rrrrr|}
    \hline
    数据集合 &\#关系& \#实体& \#训练集合& \#验证集合& \# 测试集合\\
    \hline
    WN18  & 18     & 40943  &141442 & 5000  & 5000\\
    FB15K & 1345 & 14951 & 483142 & 50000& 59071\\
    WN11  &11       & 38696 & 112581 & 2609  &10544\\
    FB13   &13       & 75043 &316232  &5908  &23733\\
    FB40K & 1336 & 39528 &370648 &67946&96678\\
    \hline
    \end{tabular}
    \end{table}

    \subsection{链接预测}
    链接预测是用来预测三元组$(h, r, t)$中缺失实体$h$或$t$的任务，并且在 \cite{bordes2011learning,bordes2012joint,bordes2013translating} 这些工作中被使用过。在本任务中，对于每一个缺失的实体，模型将被要求用所有的知识图谱里的实体作为候选项并进行排名，而不是单纯给出一个最优的预测结果。和之前 \cite{bordes2011learning,bordes2013translating} 的工作一样，我们在 WN18 和 FB15K 上进行了实验。

    在测试阶段，对于每个被测试到的三元组$(h, r, t)$，我们用知识图谱中的其他实体作为候选项来替换头实体或者尾实体，并且以降序顺序给出这些实体的评分函数$f_r$。和 \cite{bordes2013translating} 一样，我们使用了两种评测方式：(1) 正确的实体评分函数的平均排名（Mean Rank）；(2) 正确的实体排名在前$10$的比例，即十命中率（Hits@10）。一个优秀的链接预测模型应当获得较低的平均排名和较高的十命中率。实际上，一个被人为构建的负例三元组有可能是存在于知识图谱中的，实际上这不应当被视作负例。然而，上述的评测方法可能低估了这些三元组对评测结果的影响。因此，在对候选排名之前我们先将这些三元组过滤掉，然后再用上述的评测。我们将原来的评测称为``Raw''而将之后过滤之后的评测称为``Filter''。

    因为采用了相同的数据集合，我们对比了我们的模型和之前论文报告的结果，这些论文包括 \cite{bordes2013translating,wang2014knowledge}。对于 TransR 和 CTransR 的实验，我们从$\{0.1, 0.01, 0.001\}$之中为 SGD 的学习率$\lambda$；从$\{1, 2, 4\}$选择边界值$\gamma$；从$\{20,50,100\}$中选择实体和关系的维度$k$和$d$；从$\{20, 120, 480, 1440, 4800\}$中选择一批次训练的数据规模$B$。对于 CTransR，我们从$\{0.1,0.01,0.001\}$中选择约束参数$\alpha$。我们通过验证集的平均排名来决定最好的参数。
    对于 WN18，我们采用了$L_1$距离，最优的参数为$\lambda = 0.001$，$\gamma= 4$，$k = 50$，$d = 50$，$B = 1440$，$\alpha=0.001$。对于 FB15K，我们采用了$L_1$距离，最优的参数为$\lambda = 0.001$，$\gamma = 1$，$k = 50$，$d = 50$，$B = 4800$，$\alpha=0.01$。对于这两个数据集合，我们均训练$500$轮。

    WN18 和 FB15K 上的评测结果被罗列在表\ref{label_1:link_prediction}中。从表中我们可以看出：


     (1) TransR 和 CTransR 比其他模型包括 TransE 和 TransH 要表现突出很多。这表明 TransR 在效率和复杂程度上找到了一个更好的权衡。(2) CTransR 比 TransR 要表现优异，这表明我们应当构建更细粒度的模型来解决同一个关系下复杂的多样性和相关性。CTransR 只是一个初步的尝试，之后我们会在工作中尝试使用更精细的模型来解决这个问题。(3) ``bern''采样的效果在 TransH 和 TransR上都比之前的采样有提升, 尤其是在拥有更多关系的 FB15K 上。

    \begin{table*}[htb]
    \small
      \centering
      \caption{链接预测的评测结果。}
      \label{label_1:link_prediction}
      \begin{tabular}{|c|rr|rr|rr|rr|}
        \hline
        Data Sets & \multicolumn{4}{|c|}{WN18}&\multicolumn{4}{|c|}{FB15K}\\
        \hline
        
        \multirow{2}{*}{Metric} & \multicolumn{2}{|c|}{Mean Rank} & \multicolumn{2}{|c|}{Hits@10 ($\%$)} & \multicolumn{2}{|c|}{Mean Rank}& \multicolumn{2}{|c|}{Hits@10 ($\%$)} \\
        & Raw &Filter & Raw & Filter & Raw & Filter & Raw & Filter \\
        \hline
        Unstructured \cite{bordes2012joint}        &    315  &    304 & 35.3 & 38.2 & 1,074 & 979 &    4.5 &   6.3\\
        RESCAL \cite{nickel2011three}               & 1,180  & 1,163 & 37.2 & 52.8 &    828 & 683 &  28.4 & 44.1\\
        SE \cite{bordes2011learning}                  & 1,011  &    985 & 68.5 & 80.5 &    273 & 162 &  28.8 & 39.8\\
        SME (linear) \cite{bordes2012joint}         &    545  &    533 & 65.1 & 74.1 &    274 & 154 &  30.7 & 40.8\\
        SME (bilinear) \cite{bordes2012joint}      &    526  &    509 & 54.7 & 61.3 &    284 & 158 &  31.3 & 41.3\\
        LFM  \cite{jenatton2012latent}                 &    469  &   456 & 71.4 & 81.6 &    283 & 164 &  26.0 & 33.1\\
        TransE \cite{bordes2013translating}        &    263 &    251 & 75.4 & 89.2 &    243 & 125 &  34.9 & 47.1\\
        TransH (unif) \cite{wang2014knowledge} &   318 &    303 & 75.4 & 86.7 &    211 &    84 &  42.5 & 58.5\\
        TransH (bern) \cite{wang2014knowledge}&   401 &    388 & 73.0 & 82.3 &    212 &    87 & 45.7 & 64.4\\
         \hline
        TransR (unif)  &232 &219 &           78.3                &91.7&                226&            78 &            43.8 &           65.5\\
        TransR (bern) & 238             &225             &\textbf{79.8}  &92.0 &    \textbf{198}& 77 &  48.2 & 68.7 \\
     CTransR (unif) & 243 & 230& 78.9&\textbf{92.3} & 233&  82  &44&66.3\\
     CTransR (bern) & \textbf{231}            &\textbf{218}             &79.4  &\textbf{92.3} &   199  & \textbf{75} & \textbf{48.4} &\textbf{70.2} \\
        \hline
      \end{tabular}
    \end{table*}

    在表\ref{label_1:mapping_property}中，我们将关系分类并且分别表现了实验结果。\footnote{关系的映射方法我们遵循 \cite{bordes2013translating} 中的规则。} 在FB15K上，我们可以发现 TransR 在所有分类后的关系上都获得了最好的结果，尤其是 (1) 预测 ``1-to-1'' 关系时，TransR为实体和关系及其复杂的相关性提供了更精确的表示。正如图\ref{fig_1:idea}所示的那样；(2) 预测 ``1-to-N'' 和 ``N-to-1'' 关系时，TransR通过关系特定投影来区分相关实体的能力得到了体现。

    \begin{table*}[htb]
    \small
    \centering
    \caption{将关系分类后在 FB15K 上的评测结果。($\%$)}
     \label{label_1:mapping_property}
    \begin{tabular}{|c|rrrr|rrrr|}
    \hline
    Tasks &\multicolumn{4}{|c|}{Predicting Head(Hits@10)}&\multicolumn{4}{|c|}{Predicting Tail(Hits@10)}\\
    \hline
    Relation Category&1-to-1&1-to-N&N-to-1&N-to-N&1-to-1&1-to-N&N-to-1&N-to-N\\
    \hline
    Unstructured \cite{bordes2012joint}           & 34.5  &   2.5 &   6.1 &   6.6 & 34.3 &   4.2 &   1.9 &   6.6\\
    SE \cite{bordes2011learning}                     & 35.6  & 62.6 & 17.2 & 37.5 & 34.9 & 14.6 & 68.3 & 41.3\\
    SME (linear)   \cite{bordes2012joint}          & 35.1  & 53.7 & 19.0 & 40.3 & 32.7 & 14.9 & 61.6 & 43.3\\
    SME (bilinear) \cite{bordes2012joint}         & 30.9  & 69.6 & 19.9 & 38.6 & 28.2 & 13.1 & 76.0 & 41.8\\
    TransE \cite{bordes2013translating}          &43.7   & 65.7 & 18.2 & 47.2 & 43.7 & 19.7 & 66.7 & 50.0\\
    TransH (unif)  \cite{wang2014knowledge} & 66.7  & 81.7 &  30.2 & 57.4 & 63.7 & 30.1 & 83.2 & 60.8\\
    TransH (bern) \cite{wang2014knowledge} & 66.8  & 87.6 &  28.7 & 64.5 & 65.5 & 39.8 & 83.3 & 67.2\\
    \hline
    TransR (unif)  & 76.9&  77.9&\textbf{38.1}&66.9&76.2&38.4&76.2&69.1
    \\
    TransR (bern) & 78.8&\textbf{89.2}&34.1&69.2&79.2&37.4&\textbf{90.4}&72.1
     \\
    CTransR (unif) &78.6&77.8&36.4&68.0&77.4& 37.8& 78.0&70.3\\
    CTransR (bern)& \textbf{81.5}&89.0&34.7&\textbf{71.2}&\textbf{80.8}&38.6&90.1&\textbf{73.8}
    \\
    \hline
    \end{tabular}
    \end{table*}

    \begin{table}[htb]
    \small
    \centering
    \caption{$\langle$头实体, 尾实体$\rangle$对于``location\_location\_contains''关系聚类的样例。}
     \label{label_1:cluster_example}
    \begin{tabular}{|c|p{0.88\columnwidth}|}
    \hline
    & \multicolumn{1}{|c|}{$\langle$头实体, 尾实体$\rangle$} \\
    \hline
    1 & $\langle$Africa, Congo$\rangle$, $\langle$Asia, Nepal$\rangle$, $\langle$Americas, Aruba$\rangle$,  $\langle$Oceania, Federated States of Micronesia$\rangle$
    \\ \hline
    2 & $\langle$United States of America, Kankakee$\rangle$,
    $\langle$England, Bury St Edmunds$\rangle$,
    $\langle$England, Darlington$\rangle$, $\langle$Italy, Perugia$\rangle$ \\ \hline
    3 & $\langle$Georgia, Chatham County$\rangle$, $\langle$Idaho, Boise$\rangle$, $\langle$Iowa, Polk County$\rangle$, $\langle$Missouri, Jackson County$\rangle$, $\langle$Nebraska, Cass County$\rangle$
    \\ \hline
    4 & $\langle$Sweden, Lund University$\rangle$, $\langle$England, King's College at Cambridge$\rangle$, $\langle$Fresno, California State University at Fresno$\rangle$, $\langle$Italy, Milan Conservatory$\rangle$
    \\\hline
    \end{tabular}
    \end{table}

    表\ref{label_1:cluster_example} 给出 FB15K 中``location\_location\_contains''关系的一些聚类示例。我们可以发现：聚类\#1是关于大陆包含国家, 聚类\#2是国家包含城市，聚类\#3是区域包含乡村, 聚类\#4是国家包含大学。很明显，通过聚类，我们可以学习更精确和细粒度的关系嵌入，有助于进一步提高知识图谱的填充性能。


    \subsection{三元组分类}
    三元组分类是一个判断给定三元组$(h, r, t)$正确与否的任务。这是一个二分类任务，已经在 \cite{socher2013reasoning,wang2014knowledge} 等工作中作为评测方式。在这个任务上我们采用了 WN11，FB13 和 FB15K 来进行测试，并且和 \cite{wang2014knowledge}的设置保持一致。

    我们需要负例三元组来进行二分类测试。在 NTN \cite{socher2013reasoning} 中，数据集合 WN11 和 FB13 已经有了负面的三元组。但对于 FB15K 来说却没有之前工作公开发布的负例三元组，我们采用了 \cite{socher2013reasoning} 中使用到的负例生成算法设定。对于三元组分类，我们设置了一个特殊的阈值$\delta_r$。对于三元组$(h,r,t)$，如果评分函数的结果低于$\delta_r$，那么三元组将会被认为是正确的，反之则是错误的。$\delta_r$ 通过最大化验证集上的分类精度来进行优化。


    对于 WN11 和 FB13, 我们比较了我们的模型以及 \cite{wang2014knowledge} 中汇报的结果在相同的参数设定下。如 \cite{wang2014knowledge} 中提到的，为了公平比较，所有报告的结果都不与字嵌入进行组合。

    由于 FB15K 是根据 \cite{socher2013reasoning} 中的策略自行生成的，因此评估结果无法直接与 \cite{wang2014knowledge} 中报告的结果进行比较。因此，我们实现 TransE 和 TransH，并使用 \cite{socher2013reasoning} 发布的NTN代码，并对我们的FB15K数据集进行评估进行比较。

    对于 TransR 的实验来说，我们从$\{0.1, 0.01, 0.001, 0.0001\}$之中为 SGD 的学习率$\lambda$；从$\{1, 2, 4\}$选择边界值$\gamma$；从$\{20,50,100\}$中选择实体和关系的维度$k$和$d$；从$\{20, 120, 480, 1440, 4800\}$中选择一批次训练的数据规模$B$。我们通过验证集的平均排名来决定最好的参数。
    对于 WN11，我们采用了$L_1$距离，最优的参数为$\lambda = 0.001$，$\gamma= 4$，$k = 20$，$d = 20$，$B = 120$，$\alpha=0.001$。对于 FB13，我们采用了$L_1$距离，最优的参数为$\lambda = 0.0001$，$\gamma = 2$，$k = 100$，$d = 100$，$B = 480$，$\alpha=0.01$。对于这两个数据集合，我们均训练$1000$轮。

    三元组分类的评估结果如表\ref{label_1:triple_classification}所示。从表\ref{label_1:triple_classification}，我们观察到：(1) 在WN11上，TransR 显著优于包括 TransE 和 TransH 在内的方法。(2) TransE，TransH 和 TransR 都不能超过 FB13 上最具表现力的型号NTN。相比之下，在较大的数据集 FB15K 上，TransE，TransH 和 TransR 的性能要好于NTN。结果可能与数据集的特征有关：FB15K 中有 $1,345$种关系类型，而 FB13 中只有$13$关系类型。同时，两个数据集中的实体数量和关系事实相近。如 \cite{wang2014knowledge} 中讨论到的，FB13 中的知识图谱比 FB15K 甚至 WN11 更稠密。某种程度上最具表现力的模型 NTN 可以从 FB13 的密集图中使用张量变换来学习复杂的相关性。相比之下，更简单的模型能够更好地处理 FB15K 这样的稀疏图，并具有良好的泛化能力。(3) 此外，``Bern''采样技术提高了 TransE，TransH 和 TransR 在所有三个数据集上的性能。

    如 \cite{wang2014knowledge} 所示，TransE 和 TransH 的训练时间分别为$5$分钟和$30$分钟。TransR 的计算复杂度高于 TransE 和 TransH，训练耗时大约为$3$小时。

    \begin{table}[htb]
    \small
    \centering
    \caption{三元组分类的评测结果。 ($\%$)}
    \label{label_1:triple_classification}
    \begin{tabular}{|c|r|r|r|r|}
    \hline
    Data Sets & WN11 & FB13 & FB15K \\
    \hline
    SE                   & 53.0 &           75.2  & - \\
    SME (bilinear) & 70.0 &           63.7  & - \\
    SLM                & 69.9 &           85.3  & - \\
    LFM                & 73.8 &           84.3  & - \\
    NTN                & 70.4 &\textbf{87.1} &68.5 \\
    TransE (unif)  & 75.9 &           70.9  & 79.6 \\
    TransE (bern) & 75.9 &           81.5  & 79.2 \\
    TransH (unif)  & 77.7 &           76.5  & 79.0 \\
    TransH (bern) & 78.8 &           83.3  & 80.2 \\ \hline
    TransR (unif)  &85.5  &           74.7  & 81.7 \\
    TransR (bern) &\textbf{85.9}&82.5  & 83.9 \\
    CTransR (bern) & 85.7 & -&\textbf{84.5}\\
    \hline
    \end{tabular}
    \end{table}

    \subsection{文本中的关系抽取}

    关系提取旨在从大规模纯文本中提取关系事实，这是丰富知识图谱的重要信息来源。当前大量的方法 \cite{mintz2009distant,riedel2010modeling,hoffmann2011knowledge,surdeanu2012multi}将大量文本语料库中的句子通过知识图谱作为距离监督来自动注释形成训练数据，然后提取文本特征来构建关系分类器。这些方法只使用纯文本来推断新的关系事实，与此同时，知识图谱嵌入则是仅基于现有的知识图谱进行链接预测。


    所以，利用纯文本和知识图谱来推断新的关系事实是很直接的想法。在 \cite{weston2013connecting} 中，模型将 TransE 和基于文本的提取模型相结合，对候选事实进行排序，取得了有效的效果提升。TransH \cite{wang2014knowledge} 也发现了类似的效果改进。在本节中，我们将结合基于文本的关系提取模型来研究 TransR 的性能。

    我们使用了 NYT+FB 数据集合，这个数据集合也被用在 \cite{weston2013connecting} 的工作中来构建基于文本的关系提取模型。在这个数据集中，纽约时代周刊文本内容（New York Times Corpus）中的实体用 Stanford NER 来注释并链接到 Freebase 中的实体上。

    在我们的实验中，我们实现了 \cite{weston2013connecting} 提出的基于文本的提取模型，并且命名为Sm2r。对于知识图谱部分，\cite{weston2013connecting} 使用了上限最高$4$百万个实体的子集，同时有$23000$个关系类型。由于 TransH 尚未发布数据集，且 TransR 将需要花费很长时间才能从$4$百万个实体的数据中学习到嵌入，我们自己生成了一个较小的数据集 FB40K，其中包含 NYT 中的所有实体和$1336$个关系类型。为了测试公平，从 FB40K 我们删除实体对出现在 NYT 测试集中的所有三元组。 与以前的结果 \cite{weston2013connecting,wang2014knowledge} 相比，我们发现使用 FB40K 进行学习并不会显着降低 TransE 和 TransH 的有效性。因此，我们可以安全地使用 FB40K 来证明 TransR 的有效性。

    按照在\cite{weston2013connecting}中相同的方法，我们将基于文本的关系提取模型的分数与知识图谱嵌入的分数相结合来进行排序，并获得 TransE，TransH 和 TransR 的准确率召回率曲线。由于我们的数据集的 Freebase 部分是由我们自己构建的，与 \cite{wang2014knowledge} 不同，评估结果不能直接与 \cite{wang2014knowledge} 中报告的结果进行比较。因此，我们自己实施 TransE，TransH 和 TransR。我们将嵌入维度 $k, d = 50$，学习率$\lambda = 0.001$，边界距离$\gamma = 1.0$，$B = 960$，并且采用了$L_1$距离。评估曲线如图\ref{fig_1:relation_extraction}所示。

    \begin{figure}[htb]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/trans/RE_text}
    \caption{TransE, TransH 和 TransR 在关系抽取任务上的准确召回率曲线。}
    \label{fig_1:relation_extraction}
    \end{figure}

    从表中我们观察到，当召回范围为$[0,0.05]$时，TransR 优于 TransE，与 TransH 相当，并且当召回范围为$[0.05,1]$时，则超越所有的模型，包括 TransE 和 TransH。

    最近嵌入的想法也被广泛地用于表示单词和文本的工作中 \cite{bengio2003neural,mikolov2013efficient,mikolov2013distributed,mikolov2013linguistic}，这些都可以在未来用于基于文本的关系提取任务中。

    \section{结论}
    在本文中，我们提出了一种新的知识图谱嵌入模型 TransR。TransR 将实体和关系嵌入不同的实体空间和关系空间中，并通过投影实体转换到关系空间来进行学习嵌入。此外，我们还提出了 CTransR，其目的是基于分段线性回归的思想来模拟每个关系类型内部的复杂的相关性。在实验中，我们对三个任务进行评估，包括链接预测，三元组分类和文本中的关系提取。实验结果表明，与 TransE 和 TransH 相比，TransR 获得了相当一致和显著的效果改进。


% \chapter{其它附录}
% 前面两个附录主要是给本科生做例子。其它附录的内容可以放到这里，当然如果你愿意，可
% 以把这部分也放到独立的文件中，然后将其 \cs{input} 到主文件中。
