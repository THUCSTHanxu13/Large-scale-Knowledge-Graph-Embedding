\chapter{引言}
\label{cha:intro}


\section{研究背景}

\subsection{知识图谱的发展沿革}

从古至今，信息的主要交流方式是基于语言的，人类知识的长期传承也是通过语言文字这个载体进行下去的。可以说，从人类早期的莎草纸、羊皮卷、竹简到之后的纸张，上面的文本内容成了知识千年以来突破时空的重要途径。而伴随着互联网在二十一世纪的蓬勃发展，信息的传递速度、传递带宽、一次载体能够传递的信息量都得到了极大提升。信息的增长趋势也从过去的线性级别增长变成了指数级别的增长，这意味着每天都有成千上万的信息涌入了网络之中。这些海量的数据一方面使得信息的来源变的空前丰富，但同时也使得我们对信息的把握、筛选遇到了巨大障碍。信息爆炸同时伴随噪音爆炸，在这样的环境下，从海量的嘈杂的文本中提取知识是不容易的。在这样的背景下，为了有效地获取知识，知识图谱（KG）的概念被提出并在学术界和工业界都受到了广泛的关注。

知识图谱（Knowledge Graph, KG），某些场景下也被称为知识库（Knowledge Base，KB），是一种将现实世界中人类的知识结构化之后形成的知识系统。在知识图谱中，大量的知识，诸如开放数据库和百科全书中的信息，通常以关系数据集合的形式被表达出来。而在关系数据集合中，基本事实被抽象为实体（Entity），而规则、逻辑、推理等关联性的信息则被抽象为实体间的关系（Relation）。若将实体对应于点，关系对应于边，则这些知识可以进一步以图的形式呈现，从而可以被计算机高效的使用，而这也是研究知识图谱的意义所在。这种将实体和抽象概念结构化成多关系数据库的模式也是近年来被大力提倡的，我们接触到的信息，尤其是文本信息突破了以往字符串线形构成的基本形式，可以以实体和关系构成的网状形式存在。

目前知识图谱已经作为人工智能领域的一项基础核心技术，被广泛引入到信息检索（Information Retrieval，IR）、问答系统（Question Answering，QA）、推荐系统（Recommender System，RS）等任务上。图谱中优质的结构化知识信息，能够指导我们的智能模型具备更深层的事物理解、更精准的任务查询以及可能的逻辑推理能力，从而在这些知识驱动应用中起着至关重要的作用。可以毫不夸张的说，正是由于这些结构化知识图谱的存在，我们建模实体以及实体之间的关系变的容易，让计算机能够理解知识、运用知识甚至于发掘创造知识的想法也逐渐具有了可行性。

\vspace{25pt}
\begin{figure}[!htbp]
\setlength{\abovecaptionskip}{30pt} 
\centering
\includegraphics[width=0.8\columnwidth]{figures/ch1/KG_example.png}
\caption{一些常用的大规模知识图谱}
\label{ch1:KG_example}
\end{figure}

而随着时间的积累和相关工作者长期的工作，结合机器自动标注、专家标注和开放平台编辑校对等多种方法，现在已经构建出一些诸如图\ref{ch1:KG_example}中的高质量的大规模知识图谱，诸如 WordNet \cite{miller1995wordnet}，YAGO \cite{hoffart2013yago2}，DBPedia \cite{auer2007dbpedia}，Freebase \cite{bollacker2008freebase}，Wikidata \cite{vrandevcic2014wikidata} 以及 Knowledge Vault \cite{dong2014knowledge}，并且被投入到部分相关研究场景中。截止到Freebase停止更新为止，Freebase中收集了超过 $2$ 亿个的实体，在其停止维护后这些信息正在被陆续迁移到 Knowledge Vault 和 Wikidata 中。经过维基社区的过滤和校对，截止目前，Wikidata中也有超过 $2600$ 万个高质量实体存在。与此同时，国内从事互联网领域尤其是和信息检索直接相关的企业也对知识图谱进行了投入，百度知心和搜狗知立方作为典型的中文知识图谱被构建出来并被使用到智能应用产品中进行知识驱动。

知识图谱将具象事物与抽象概念表示为实体，将实体之间的联系表示为关系，并以（ \emph{头实体}, \emph{关系}, \emph{尾实体} ）的形式表述知识。例如，“马克·吐温出生于佛罗里达州”在知识图谱中被表述为（ \emph{马克·吐温}, \emph{出生于}, \emph{佛罗里达州} ）；“北京市下辖海淀区”在知识图谱中被表述为（ \emph{北京市}, \emph{区划管辖}, \emph{海淀区} ）等等。其中\emph{马克·吐温}、\emph{佛罗里达州}、\emph{北京市}、\emph{海淀区}即为实体，而\emph{出生于}、\emph{区划管辖}则是实体间的关系。一般来说，现在公开的知识图谱都是以这样的事实三元组(triple fact)的 形式抽象知识，并采用类似于万维网联盟（W3C）发布采用的资源描述框架(Resource Description Framework, RDF)进行储存。图\ref{ch1:google_kg_example}中展现的就是使用谷歌搜索``北京''时弹出的相关知识图谱。

\vspace{25pt}
\begin{figure}[h]
\setlength{\abovecaptionskip}{30pt} 
% \setlength{\textfloatsep}{60pt} 
\centering
\includegraphics[width=0.6\columnwidth]{figures/ch1/knowledge.png}
\caption{日常搜索中出现的知识图谱}
\label{ch1:google_kg_example}
\end{figure}

伴随着上个世纪末互联网的蓬勃发展以及本世纪初信息技术的大量普及，在大量知识被整理进入知识图谱的同时，每天也有大量的知识产生。虽然当前的知识图谱离完善还差的很远，但以结构化形式存在于知识图谱中的知识也是相当惊人的多。而伴随着信息爆炸式增长以及日新月异的变化，海量的数据如何整理、存储、更新以及应用都是巨大的挑战。而这些知识图谱带来的技术诉求，其中很重要的一点就是如何以一个高效的方式进行知识图谱的表示。基于事实三元组集合的形式来表示知识图谱可以解决底层数据存储形式的问题，这与关系数据库的模式是十分相似的。但这样简单的抽象形式对于理解图谱、应用图谱乃至于依靠知识进行逻辑推理确是远远不够的。想要以高效的形式对知识图谱进行更高层的抽象，并且能够做到利用知识，这其中面临着许多难题：其一，是在计算效率上的问题。知识图谱往往以有向图的形式存在，以点为实体边为关系，这样的形式简单明了，却也需要图相关的算法来进行处理。早期基于图结构的图谱表示算法，其计算复杂度通常都非常高，以至于在大规模的知识图谱上难以适用。其二，知识图谱中实体和关系都很多，却没有实体数平方级别的事实三元组，这意味着知识图谱是稀疏图而非稠密图。与此同时，实体之间也相差很大，满足幂律分布。少部分高频实体和关系涵盖了多数的事实三元组，其余均是长尾部分。数据的稀疏性以及长尾分布也为模型设计带来巨大难度。

\vspace{25pt}
\begin{figure}[h]
\setlength{\abovecaptionskip}{30pt} 
\centering
\includegraphics[width=0.9\columnwidth]{figures/ch1/space.png}
\caption{BabelNet 中与实体``法国''空间距离最近的实体}
\label{ch1:space}
\end{figure}

研究和解决抽象知识图谱过程中的计算复杂度与数据稀疏性问题，并将知识图谱表达为计算机可使用的模式，就是知识表示学习(Knowledge Representation Learning, KRL)的主要任务。近些年来，受到文本词向量的启发，将图谱进行分布式表示逐渐成为趋势。对于知识图谱来说，所谓的分布式表示(Distributed Representation)，其实质就是将图谱中的实体和关系映射到低维度的连续空间中去。在映射空间上，对象之间的距离关系可以直接反映语义关联，比如语义相似的实体，其空间距离一般都十分相近。图\ref{ch1:space}展现的就是空间上与``法国''最相关的实体，数据来源于 BabelNet \footnote{http://babelnet.org/}。因为这个过程实际是将实体与关系的语义信息嵌入到低维度空间上，所以我们通常也将这个过程称为嵌入，得到的向量称为嵌入表示或直接称为嵌入（Embedding）。分布式表示一定程度上解决了之前提到的问题：首先，将知识图谱嵌入到低维度空间上，低维度的空间让实体与关系之间的语义关联计算更加便利，计算量也显著减少。其次，赋予每个实体与关系实数向量的表示，并且向量之间的空间关系来表示语义关联，很大程度上让知识图谱的分布不再稀疏。最后，以数值形式存在的知识图谱对于计算机来说比字符更容易理解和计算，将其作为其他各个应用模型的输入也变的容易起来。得益于知识表示学习在分布式表示上的有效推进，相关领域的工作也不断推陈出新，涌现了一批知识驱动为内核的模型。

虽然在知识表示学习的研究中已经有大量优秀的模型出现，且在实验数据集合上体现出了良好的性能。但是在实验环境中，数据集往往与实际的知识图谱相差甚远，通常只是公开大规模知识图谱的子集。通过实际对比可以发现，大规模的知识图谱无论在规模还是在分布上都比实验数据集合难处理的多，呈现出规模巨大、长尾突出的状态。与此同时，实验过程中模型的设计在突出性能考虑的时候往往忽略了模型复杂度，其工程实现也难以承受巨大规模的数据量。另一方面，知识图谱常常会与多源信息进行融合，尤其是与自由文本进行融合。以往的知识图谱与文本的融合模型均以串行形式进行融合，这也是很难在极大数据量的背景下进行训练与处理的。本文工作的主要目的就是立足于现有模型的基础上提出一套针对大规模知识图谱的表示学习框架、特征融合框架，在真实的大规模知识图谱上进行训练并得到优质的嵌入表示。

\subsection{公开的大规模知识图谱}

	\textbf{WordNet}\footnote{http://wordnet.princeton.edu/}是一个以英语词汇与语义为主题的知识图谱，且覆盖范围非常宽广，由美国普林斯顿大学（Princeton University）的科研人员创建。在WordNet中，无论是名词、动词、形容词亦或是副词，都会按照其自身语义划分到同义词集中去（Synsets）。整个图谱以同义词集为单位，提供比较精炼的定义和使用示例，形成一个基础的语义单元。同义词集之间，以及同义词集与成员之间，存在一些语言上的关系连接，比如同义词、反义词、蕴涵关系、词元标签以及上下位关系等等。

	\textbf{YAGO}\footnote{http://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/}是一个综合型知识图谱，由德国马克斯·普朗克研究所(Max Planck Institutes)的科研人员创建，其主要数据来源于对维基百科以及一些网络自由文本的自动提取。总体上，YAGO拥有超过1000万个的实体，以及超过1.2亿个实体间的知识事实。2012年之后，YAGO将WordNet的部分语义信息以及GeoNames的地理信息融入进来。虽然YAGO是自动构建的知识图谱，但对其进行抽样，内部的事实准确度高于95％。YAGO被应用在许多实际应用中，尤其是IBM的Watson，并且与另一个公开的知识图谱DBpedia也有着良好的实体对应。

	\textbf{DBPedia}\footnote{http://wiki.dbpedia.org/}是由德国柏林自由大学（Free University of Berlin）以及莱比锡大学（Leipzig University）的科研人员创建。与YAGO类似，DBPedia也是基于维基百科结构化出的知识图谱，主要功能是强化维基百科的搜寻功能，并将外部的自由文本链接至维基百科。之后DBpedia不断发展，现已成为横跨多种语言多种领域的大型综合知识图谱，并且应用在地图整合、多面向搜寻、关系查询、文件分类与标注等多个应用领域上。目前，DBpedia 在 中的事实三元组 数量已经超过了30亿条。除上述优点外，DBpedia 还能够自动与维基百科保持同步，覆盖多种语言。到目前为止，DBpedia含有超过125种语言的知识事实达30亿个。

	\textbf{Freebase}\footnote{https://developers.google.com/freebase/}是由自然语言公司MetaWeb起初创建的，之后被谷歌（Google）收购，成为谷歌自身知识图谱工程的重要组成部分。与YAGO、DBpedia不同，Freebase是一个庞大的合作知识图谱，主要由社区成员编辑的数据构成，辅助以自动抽取工具。迄今为止，Freebase 是公开的最大规模的知识图谱，包含超过2亿个的实体，以及超过30亿的知识事实。Freebase的数据可以根据创作共用署名许可协议进行商业和非商业用途，并为程序员提供了极为开放的API、RDF备份以及数据库转储，因此成为学术界与工业界图谱研究的主要信息来源。不过2015年底，谷歌正式宣布了其自身的知识图谱 API 来替代 Freebase 的API，Freebase 也正式关闭，并逐步移入至 WikiData 中。

	\textbf{Wikidata} \footnote{https://www.wikidata.org/wiki/Wikidata:Main\_Page/} 是维基媒体基金会支持下组织的一个多语言综合知识图谱，主要目的是为维基媒体下的诸多项目（包括维基百科），提供一个概括性的数据框架。在这个框架基础上，大量的文本、图片、影像都被组织在一起。与其他的知识图谱不同，Wikidata的主要组织形式是文档页面。每个实体均有单独的页面，内部是大量的属性和链接，通向其他实体或者维基资源。到目前为止，Wikidata已有超过2500万个实体。Wikidata有几大显著特点：首先，其是一个十分精确的知识图谱，比自动抓取的知识图谱要精确的多，且近年来增长速度极快。此外，其可以统一所有的维基资源，在知识图谱与其他特征进行融合时可以提供大量数据。Wikidata与所有维基媒体项目一样可以免费使用。 


\section{研究内容}

在前文中，我们点明了知识图谱的重要作用，以及在大规模知识图谱上面临的诸多问题与难点。本工作的主要关注点就是大规模知识图谱表示学习的相关问题，并对应提出两个方面上的重要模型：（1）针对知识表示的基于并行的大规模知识图谱表示学习框架；（2）针对特征融合的基于并行的知识图谱与文本模型联合学习框架。

\subsection{知识表示学习}

第一个是针对知识表示学习的基于并行的大规模知识图谱表示学习框架。知识图谱在信息检索、问答系统等许多应用中起着十分重要的作用，而这些应用程序需要以知识图谱中实体与关系的嵌入表示来作为输入，从而能够确保模型进行高效计算。知识图谱本身缺损大量的信息，这个问题同样需要将图谱嵌入到低维度空间中进行表示，并在向量表示的基础上进行推理和填充。出于这两方面的诉求，在以往的工作中已经涌现出一批能够将知识图谱嵌入到连续低维空间的有效方法。而这些算法出于实现细节问题，虽然在小型知识图谱上得到了效果验证，但却并不足以支撑在大规模知识图谱上的操作。为了解决大规模知识图谱表示学习的问题，我们提出一个统一的高效框架，并对已有的一系列经典模型进行改造，使之融入到我们的体系中进行加速，最终可以在可接受的有限时间内训练出可用的嵌入表示。整体的框架一改以往线性训练模式，采用多线程带来的并发训练模式。除此以外，我们的框架还在底层对于采样进行了优化，重复的算术运算也得到了合并。为了评估我们模型的高效性和准确性，我们在传统的数据集合上进行了评估。评估结果可以表明，我们的框架可以显著提高知识图谱表示学习的训练效率，且对准确率不会造成影响，除了多线程带来的受益外，算法底层的操作可以额外得到十倍的加速。评估之外，我们也对完整的大规模知识图谱Freebase、Wikidata进行了训练，并提供了训练完成后的嵌入表示。

\subsection{知识特征融合}

第二个是针对特征融合的基于并行的知识图谱与文本模型联合学习框架。知识图谱的相关资源是十分丰富的，尤其是大量的自由文本。大量的工作在关注知识图谱中的事实三元组结构信息之外，也会将与实体、关系相关的文本信息引入到模型内。除了知识表示外，文本关系抽取就是一个利用文本信息丰富知识图谱的任务。在本文中，我们将知识表示以及文本关系抽取统一为知识获取任务，并提出一个通用的联合学习框架来进行图谱和文本的表示。以往的联合模型都是以串行连接的方式将图谱模型与文本模型进行联合，而在我们的框架中，我们采用平行的连接方式，从而能够以极快的速度进行训练。在我们的框架中，知识图谱和文本模型被统一到一个低维连续空间，学习实体、关系以及词语的嵌入表示。在训练过程中，框架通过实体与词语的匹配、关系与文本关系的匹配来分享参数，以达到特征融合的目的。这样的联合机制可以使得各个部分的模型可以同时考虑知识图谱和文本的特征，从而同时在知识表示和文本关系抽取都取得优异的效果。我们的框架，与现有的进行知识获取的联合学习模型还有一个重大差别，我们的框架十分灵活，图谱部分模型以及文本部分模型均可以被替换为现有的经典模型。在实验中，我们也针对性地在知识图谱填充以及关系抽取任务上进行了测试。实验结果表明，在我们联合框架下训练的模型比单独进行训练的模型，在效果上有显著提升。

\subsection{要点总结}

  本文工作要点总结如下:

  （1）通过底层实现的优化以及对知识图谱的划分，将以往的图谱模型改造成基于多线程的训练模型，在未来可以进一步衍生为分布式的训练模型，从而能够高效的对大规模知识图谱进行学习。
  
  （2）提出了加权点采样算法和位移负样例采样算法来取代原有的边采样及负例采样算法。能够在大规模图谱的幂率分布下对图中不同的实体和事实赋予不同的注意度，缓解幂率分布带来的长尾影响。二点采样的训练方式，可以在训练过程中尽可能的合并算术运算从而进一步加速。
  
  （3）采用了平行结合的方式与文本神经网络模型融合，对比于传统的串行结合方式，这样的模型能够更快的引入文本信息来丰富图谱内容并进行信息融合。在此基础上我们提出了一套联合学习的方法，使得图谱和文本的信息融合是双向的，图谱和文本模型融合之后两者都有显著效果提升
  
  （4）本文的相关工作提供了开源代码并对之前领域内的相关工作进行整理和总结，为之后相关领域需要使用知识图谱的后续研究打好基础，提供便利。

\section{论文组织}

本论文的整体章节结构安排如下:

第一章：引言

本文的引言部分主要是从一个宏观的角度，整体阐述知识图谱的发展沿革、当下的发展状态，对论文的研究背景、涉及的重要概念以及选题的意义进行诠释。与此同时，引言部分也简要介绍了知识表示学习、知识特征融合的研究内容，研究状态，以及存在的难点与问题。

第二章：基于并行的大规模知识图谱表示学习框架

在此章节，我们将详细介绍我们基于并行的大规模知识图谱表示学习框架的研究工作，包括研究背景、主要问题与挑战、相关的表示学习模型。这部分内容着重介绍过去几年中被提出的几大类知识表示模型和各自的优劣之处，点明大规模知识图谱表示学习需要解决的核心问题。之后介绍本工作中提出的基于多线程的并行框架与算法原理，以及实验设置和实验结果分析等。我们通过统一的数学形式将多种知识图谱表示模型，统一吸收到我们的框架中，并在知识图谱补齐的链接预测任务上进行评测与实验结果分析，也细节观察了不同线程设置下加速性能的变化以及底层优化带来的加速提升。

第三章：基于并行的知识图谱与文本模型联合学习框架

在此章节，我们将详细介绍我们基于并行的知识图谱与文本模型联合学习框架的研究工作，包括研究背景、主要问题与挑战、相关的联合学习模型。这部分内容着重介绍过去几年中被提出的知识图谱和文本模型的结合方法及相关任务，综述神经网络引入后深度模型的发展和联合学习模型的发展。之后介绍本工作中提出的联合框架模型与算法原理，以及实验设置和实验结果分析等。我们探索了平行结合方式下的联合学习模型，并在知识图谱补齐、文本关系抽取等任务上进行评测与实验结果分析，也细节观察了联合学习前后模型在各个任务上的表现。

第四章：总结与展望

在此章节，我们对全文大规模知识图谱表示学习的框架、特征融合等工作进行总结，分析我们取得的阶段性成果，也罗列我们提出模型可能存在的问题，并展望未来可以进行的一系列工作。

