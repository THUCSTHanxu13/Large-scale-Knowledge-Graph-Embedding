\chapter{总结与展望}
\label{cha:conclusion}

\section{工作总结}

人类将自身掌握的知识体系再次高度结构化并形成知识图谱，是信息化技术影响下的必然趋势。得益于知识图谱及其相关技术的发展，数千年积累和传承的知识与智慧变的不再松散，并呈现出更多的关联性。知识图谱技术是当下人工智能以及数据挖掘技术的重要组成部分，并被广泛使用在信息检索、问答系统以及智能对话等领域，帮助学界在知识驱动指导下进行研究。而伴随着本世纪初开始的信息爆炸，在信息规模极大且十分冗杂的环境下，挖掘知识、存储知识乃至于理解知识，成为当下流行的知识图谱研究核心。目前的研究工作也面临诸多难题，尤其是大规模数据背景下的畸形分布、计算效率底下等问题。借鉴于词向量算法来解决计算效率和稀疏数据分布问题，基于分布式表示的知识图谱表示学习模型被设计出来，用来将实体与关系的语义信息嵌入到低维连续空间进行操作，并且表现出非常显著的效果。

虽然过去的工作长期攻关核心难点，并在实验阶段取得了一定成果。然而，这些知识图谱表示学习模型与特征融合模型，往往重点在于模型的表现力以及实验集合上的效果，忽略了实现的效率以及在实际大规模知识图谱上的可行程度。在本文的工作中，我们立足于模型效率以及大规模知识图谱的训练，主要关注以下两点：（1）适用于大规模知识图谱表示学习的训练框架；（2）快速有效的特征融合联合学习框架。

在第二章中，我们重点关注适用于大规模知识图谱表示学习的训练框架。已有的知识图谱表示学习模型，一般分为基于图结构、基于张量与矩阵分解以及基于平移三大类。这三类模型各自都有一些特点，尤其是基于平移的知识图谱表示学习模型，模型通常简洁有效且有一系列的模型簇。我们解决大规模知识图谱表示学习的问题不是依靠新的模型，而是优化基于平移的知识图谱表示学习模型来满足我们的需求。这些算法已在小型知识图谱上得到了效果验证，模型的表达能力是可靠的，但却不能在大规模知识图谱上进行训练，其主要影响因素就是低效的实现细节以及缓慢的训练设置。由这一点突破，在将一系列基于平移的模型统一形式之后，我们提出了一个统一的高效框架，用以在底层进行高效实现以及快速训练。整体的框架一改以往线性训练模式，借助多线程实行并发的训练模式。我们的目标就是对已有的模型进行改造，使之在我们的体系中进行获得高效实现，最终可以在较短的有限时间内训练出可用的图谱表示。实验证明，我们的框架是十分有效的，所有在框架上进行训练的模型都有了极大的提速，且准确率没有发生剧烈变化。总体来看，多线程带来了很大的加速比，而底层实现优化与训练过程优化则可额外得到近十倍的加速，从而可以在数分钟内完成以往数个小时的训练量。我们的目标基本得到了实现。


在第三章中，我们重点关注高效进行图谱与文本特征融合的联合学习框架。知识图谱不仅有丰富的结构化信息，也有十分丰富的相关资源，其中最容易获取的就是大量的自由文本。在很多场景下，尤其是长尾极其严重的大规模知识图谱场景下，仅仅关注知识图谱中事实三元组的结构信息是不够的，因为高频的实体与关系组合了绝大多数事实三元组。此时，引入实体或关系相关的文本信息，进行特征融合，变的势在必行起来。所以我们将知识图谱表示学习以及文本关系抽取进行统一，并通过匹配的实体与关系将图谱与文本连接起来。以往的联合学习模型都是以串行连接的方式将图谱模型与文本模型进行联合，比如先通过文本模型获取文本特征，再将文本特征传入到图谱空间进行嵌入，这样的联合体系训练极其缓慢。而我们却采用了基于并行的联合学习框架来进行图谱与文本的表示学习。在我们的框架设定中，知识图谱和文本模型被统一到低维连续空间进行学习，从而实体、关系以及文本词语的嵌入表示可以相互共享参数。在训练过程中，知识图谱模型与文本模型同时训练，框架通过实体与文本词汇的匹配、关系与文本关系的匹配来分享参数，以达到特征融合的目的。这样平行的连接方式，使得两边模型是同步优化的，所以能够以很快的速度进行模型训练。实验结果表明，在我们联合框架下训练的模型比起单独进行训练的模型，在效果上有显著提升。我们的框架，在提高训练速度的情况下，达到了以往串行框架同样效果的性能，且更能够适用于大规模背景下的特征融合，也达到了我们预期的实现目标。

综上所述，在本文的工作中，我们从大规模知识图谱背景下的两方面出发，提出了针对核心问题的高效并行训练框架。我们的框架，具有良好的拓展性以及高速的训练性能，能够真正做到在现实大规模知识图谱上进行表示学习以及特征融合，这些都是过去的模型所不具备的。


\section{未来展望}

在本文的工作中，我们针对大规模知识图谱表示学习及其特征融合进行了研究，分别提出了并行的训练框架，使得大规模的图谱训练在时间上变的可以让人接受。尽管本文的并行知识表示学习框架与联合学习框架显著提升了训练效率，并在特征融合后显著提升了模型效果，然而本文的工作仍然有许多可以改进的空间。在未来的工作中，我们希望能够在以下几个方向上进行尝试并力求有所改进:

（1）我们提出的基于并行的大规模知识图谱表示学习框架，已经可以将基于平移的知识图谱表示学习模型进行高效训练，并在可接受时间内得到训练结果。在未来的工作中，一方面我们可以进一步将更具有表达能力的基于平移的模型引入进来，另一方面也可以对更多不同抽象模式的模型进行优化，比如基于张量的知识图谱表示学习模型，从而能够形成一个全面的模型体系。

（2）当前的知识图谱表示学习框架是通过多线程来实现并发计算，并在单机上进行训练和测试。在未来，我们可以基于现有框架的技术基础，推出基于分布式的框架体系，从而能够在集群上进行训练和测试。随着知识图谱本身数据量的增长，以及相关应用对知识图谱的日益复杂的处理手段，对分布式框架的需求是客观存在的，非常值得投入精力进行开发。我们的框架在梯度传播时有一定中心化的成分，未来一个去中心化的实现方式也是可以进行改进的研究方向。

（3）即使我们有了知识图谱的嵌入表示，数目庞大的实体向量也是计算的巨大瓶颈。考虑对嵌入向量进行压缩或者对模型参数进行剪枝都是十分重要的研究方向。在知识图谱表示学习过程中，实体和关系都是由单独的嵌入向量表示的，这样的表达方式在一定程度上割裂了参数之间的相互关联性。将实体与关系表达为若干个基础意元的嵌入组合也是一个十分有趣的尝试，如果能够得以实现，就可以在一定程度上解决长尾问题。

（4）我们可以尝试扩充文本信息的来源，考虑语料信息之间的关联。现在我们的文本模型都是基于句子级别的，而更多的信息都是裹挟在段落乃至于整个篇章级别上的。所以如何使用这样一些横跨语料进行关联的信息，也是可以进行思考与尝试的方向。此外，我们忽略了知识图谱上实体间的间接关系，将一些带有逻辑推导性质的信息，比如实体间的关系路径，引入我们的特征融合模型里也是很好的想法。

（5）出于效率的考量，我们在本文中使用了卷积神经网络来进行文本编码，实际上循环神经网络更适用于文本的序列处理。在未来，使用基础的循环神经网络亦或是长效短期记忆网络也是十分必要的，这些神经网络模型更能够与文本的序列性质相匹配。目前，文本模型都是以远距离监督的模式进行训练，尝试使用无监督模型或者生成式模型也将是未来的一个发展趋势。

