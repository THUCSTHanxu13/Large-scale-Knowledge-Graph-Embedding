\thusetup{
  %******************************
  % 注意：
  %   1. 配置里面不要出现空行
  %   2. 不需要的配置信息可以删除
  %******************************
  %
  %=====
  % 秘级
  %=====
  secretlevel={秘密},
  secretyear={10},
  %
  %=========
  % 中文信息
  %=========
  ctitle={大规模知识图谱表示学习},
  cdegree={工学学士},
  cdepartment={计算机科学与技术系},
  cmajor={计算机科学与技术},
  cauthor={韩\ \ \ \ 旭},
  csupervisor={刘知远\ \ 助理教授},
  % cassosupervisor={陈文光教授}, 
  % 副指导老师
  % ccosupervisor={某某某教授}, 
  % 联合指导老师
  % 日期自动使用当前时间，若需指定按如下方式修改：
  % cdate={超新星纪元},
  %
  % 博士后专有部分
  cfirstdiscipline={计算机科学与技术},
  cseconddiscipline={系统结构},
  postdoctordate={2013年7月——2017年7月},
  id={编号}, % 可以留空： id={},
  udc={UDC}, % 可以留空
  catalognumber={分类号}, % 可以留空
  %
  %=========
  % 英文信息
  %=========
  etitle={Large-scale Knowledge Graph Representation Learning},
  % 这块比较复杂，需要分情况讨论：
  % 1. 学术型硕士
  %    edegree：必须为Master of Arts或Master of Science（注意大小写）
  %             “哲学、文学、历史学、法学、教育学、艺术学门类，公共管理学科
  %              填写Master of Arts，其它填写Master of Science”
  %    emajor：“获得一级学科授权的学科填写一级学科名称，其它填写二级学科名称”
  % 2. 专业型硕士
  %    edegree：“填写专业学位英文名称全称”
  %    emajor：“工程硕士填写工程领域，其它专业学位不填写此项”
  % 3. 学术型博士
  %    edegree：Doctor of Philosophy（注意大小写）
  %    emajor：“获得一级学科授权的学科填写一级学科名称，其它填写二级学科名称”
  % 4. 专业型博士
  %    edegree：“填写专业学位英文名称全称”
  %    emajor：不填写此项
  edegree={Bachelor of Engineering},
  emajor={Computer Science and Technology},
  eauthor={Han Xu},
  esupervisor={Assistant Professor Liu Zhiyuan},
  % eassosupervisor={Chen Wenguang},
  % 日期自动生成，若需指定按如下方式修改：
  % edate={December, 2005}
  %
  % 关键词用“英文逗号”分割
  ckeywords={大规模,知识图谱,表示学习,联合学习,并行加速},
  ekeywords={large-scale, knowledge graph, representation learning, joint learning, parallel acceleration}
}

% 定义中英文摘要和关键字
\begin{cabstract}

  近年来，为了抽象现实世界的知识并以一种统一载体进行结构化存储，知识图谱的概念被提出。知识图谱在广泛发挥作用的同时，也存在一些问题亟需解决：第一，知识图谱虽然总量很大但仍有更大规模的一批知识存在缺失，需要进行深入的填补与扩展；第二，将图谱的结构化信息融入到当下松散的特征模型中去，需要有效且快速的融合算法；第三，巨大规模的知识图谱对算法时间复杂度要求较高，需要有高效的模型能够在有限时间之内对图谱进行各种操作。高效、准确地将图谱表示成计算机能够理解的数字抽象，并进行快速特征融合，是解决这些问题的核心所在。本文针对大规模知识图谱表示学习及其特征融合分别提出了训练框架。其中，图谱表示学习框架通过底层优化以及图谱划分，将以往的图谱模型转化为多线程训练模型，未来可以进一步衍生为分布式训练模型。与此同时，我们提出了基于位移的负例采样算法，来取代原有的负例采样算法。新的采样算法可以缓解幂率分布带来的长尾影响，同时可以合并重复运算以进行额外加速。特征融合框架则采用了平行结合的方式与神经网络文本模型结合。相比于传统的串行结合方式，平行结合能够更快的引入文本信息来丰富图谱内容并进行信息融合。相关的实验表明，本文提出的框架能够在效果不降低的情况下极快的加速图谱表示学习，并和文本模型有很好的融合效果，使得融合之后两者都有显著效果提升。我们已经开源了部分代码\footnote{https://github.com/thunlp/Fast-TransX \\ https://github.com/thunlp/TensorFlow-TransX}以便于其他领域的研究者使用。

\end{cabstract}

% 如果习惯关键字跟在摘要文字后面，可以用直接命令来设置，如下：
% \ckeywords{\TeX, \LaTeX, CJK, 模板, 论文}

\begin{eabstract}

   In recent years, people organize structural knowledge about the world under the unified framework and construct various large-scale knowledge graphs. However, there are some problems need to be solved for knowledge graphs: (1) Most large-scale knowledge graphs are usually far from completion and need to be further extended. (2) We need effective methods to fuse knowledge and text features so that we can incorporate knowledge graphs into practical applications. (3) We need efficient models to operate on the large-scale graphs within the limited time. The key to solving these problems is to learn large-scale knowledge graph representations. In this paper, we propose frameworks to embed large-scale knowledge graphs and fuse them with text. For the knowledge representation framework, we divide the overall knowledge graph into several parts and adopt models for multi-threading training. Besides, we propose the offset-based negative sampling to replace original negative sampling algorithms. The new sampling mechanism can alleviate the long tail effect and merge arithmetic operations for acceleration. For the feature fusion framework, we use a parallel training method to combine neural networks and knowledge graph models. The experimental results show that our frameworks can accelerate the existing knowledge models without reducing the accuracy. Meanwhile, our methods can effectively perform joint representation learning and obtain more informative knowledge and text representations, which significantly outperforms other baseline methods. The source codes \footnote{https://github.com/thunlp/Fast-TransX \\ https://github.com/thunlp/TensorFlow-TransX} have been released for further exploration by the relevant community.


\end{eabstract}

% \ekeywords{\TeX, \LaTeX, CJK, template, thesis}
